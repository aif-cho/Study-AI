{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 9)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Boston_Dataset_Linear Regression\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "boston_train = np.loadtxt('boston_train.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "boston_test = np.loadtxt('boston_test.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "\n",
    "x_train = boston_train[:,:9]\n",
    "y_train = boston_train[:,[-1]]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer  1\n",
    "# (400, 9) * (9,9) = (400,9)\n",
    "W1 = tf.Variable(tf.random.normal([9,9]), name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal([9]), name='bias1')\n",
    "\n",
    "@tf.function\n",
    "def layer1(X):\n",
    "    return  tf.nn.relu(tf.matmul(X,W1) + b1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 2\n",
    "# (400, 9) * (9,5) = (400,5)\n",
    "W2 = tf.Variable(tf.random.normal([9,5]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([5]), name='bias2')\n",
    "\n",
    "@tf.function\n",
    "def layer2(X):\n",
    "    return  tf.nn.relu(tf.matmul(layer1(X),W2) + b2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 3\n",
    "# (400, 5) * (5,1) = (400,1)\n",
    "W3 = tf.Variable(tf.random.normal([5,1]), name='weight3')\n",
    "b3 = tf.Variable(tf.random.normal([1]), name='bias3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis 예측 함수(방정식) : 활성화 함수 사용\n",
    "@tf.function\n",
    "def hypothesis(X):\n",
    "    return  tf.sigmoid(tf.matmul(layer2(X),W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수 : (Hx - y)^2 의 평균\n",
    "def cost_func():\n",
    "    cost = tf.reduce_mean(tf.square((hypothesis(x_train) - y_train)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning rate (학습율) 을 0.01로 설정하여  optimizer객체를 생성\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost: [ 562.4147 ]\n",
      "1000 cost: [ 559.07275 ]\n",
      "2000 cost: [ 559.0691 ]\n",
      "3000 cost: [ 559.0683 ]\n",
      "4000 cost: [ 559.068 ]\n",
      "5000 cost: [ 559.0679 ]\n",
      "6000 cost: [ 559.0678 ]\n",
      "7000 cost: [ 559.06775 ]\n",
      "8000 cost: [ 559.06775 ]\n",
      "9000 cost: [ 559.06775 ]\n",
      "10000 cost: [ 559.06775 ]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(10001):\n",
    "    # cost를 minimize한다\n",
    "    optimizer.minimize(cost_func, var_list=[W1,b1,W2,b2,W3,b3])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step, 'cost: [', cost_func().numpy(), ']')\n",
    "        \n",
    "print('***** Learning Finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight = [[-0.2341768  -0.9467362   0.00946802 -0.7425406   1.3231523  -0.61854804\n",
      "   0.8540664  -0.02202236  2.4488697 ]\n",
      " [ 0.716949    1.3123246   1.0249155   1.5293121  -0.57500345  0.8987044\n",
      "  -1.250801   -0.7758782   1.260746  ]\n",
      " [-0.72988886  0.0569644   0.26827824  0.95914024 -0.37048063  0.03484769\n",
      "   0.13794525  0.84489566  0.4640491 ]\n",
      " [-1.429588   -0.4474997   1.1836917  -0.91330576  0.74427116 -0.67893195\n",
      "  -0.83569556 -0.41836837 -0.9336107 ]\n",
      " [-0.05430609 -0.01765319  2.0633636  -1.4186655  -0.90990627  1.1692344\n",
      "  -0.1118804   0.4041268  -1.4201527 ]\n",
      " [-1.6149429  -0.5448829  -0.11377282  0.18945342  0.9961622  -2.0208204\n",
      "  -2.8400812  -1.303486   -1.9945853 ]\n",
      " [ 0.41048855 -0.42638057  1.0378826  -0.34762594 -0.10890402 -1.2663026\n",
      "   0.9700548   0.5830718  -0.526593  ]\n",
      " [ 0.13591467  0.71242577 -0.3437147  -0.7860489  -1.7999878  -1.5483241\n",
      "  -2.0070124   0.4701867  -0.2937632 ]\n",
      " [-0.8562968   0.45351407 -0.5414195  -1.1852797  -0.37312365 -1.1413692\n",
      "   0.5026758   0.41827306  0.38021109]]\n",
      "Bias = [ 0.17887011  0.8336281   0.79160917  0.7749703   0.72448725  1.4217405\n",
      " -0.08917825  1.4264426  -1.0210733 ]\n"
     ]
    }
   ],
   "source": [
    "# 회귀 계수 출력\n",
    "print('Weight =', W1.numpy())\n",
    "print('Bias =', b1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "x_test = boston_test[:,:9]\n",
    "y_test = boston_test[:,[-1]]\n",
    "\n",
    "preds = hypothesis(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22.37256\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정(RMSE)\n",
    "def get_rmse(y_test,preds):\n",
    "    squared_error = 0\n",
    "    for k,_ in enumerate(y_test):\n",
    "        squared_error += (preds[k] - y_test[k])**2\n",
    "    mse = squared_error/len(y_test)    \n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse[0]  \n",
    "\n",
    "print('RMSE:', get_rmse(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#답안\n",
    "# layer 1 ---->   RMSE: 4.0023303 \n",
    "# layer 3 ---->   RMSE: 3.6358266\n",
    "#RMSE: 3.5922546\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
