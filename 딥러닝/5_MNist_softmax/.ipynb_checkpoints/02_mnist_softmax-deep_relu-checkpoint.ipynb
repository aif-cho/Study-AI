{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_softmax\n",
    "# 4 layers\n",
    "\n",
    "# MNIST(Modified National Institute of Standard Technology) Dataset\n",
    "# label : 0 ~ 9 , 손글씨체 이미지  28*28(784 byte) , gray scale\n",
    "# batch : 큰 데이터를 쪼개어 1회에 작은 단위로 가져다가 학습, next_batch()\n",
    "# epoch : batch를 반복하여 전체 데이터가 모두 소진되었을 때를 1 epoch\n",
    "# Vanishing Gradient  : 신경망이 깊어 질수록 입력신호가 사라진다(줄어든다), sigmoid 사용시\n",
    "# Relu  : Rectified Linear Unit, DNN(deep neural net) 구현시 sigmoid 대신 사용됨\n",
    "# dropout : 전체 신경망의 일부를 사용하지 않고 학습, 예측시는 전체를 사용\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터 가져오기\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 28, 28)\n",
      "<class 'numpy.ndarray'> (60000,)\n",
      "<class 'numpy.ndarray'> (10000, 28, 28)\n",
      "<class 'numpy.ndarray'> (10000,)\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOS0lEQVR4nO3df4xU9bnH8c8jgqgQg7JQYsnd3kZNjcnd4kiuQQiXegnyDxDsTUlsaCTdxh9JMcRcszex/kgMMZdWjKbJ9oLQm15rFRBMzC1KSAyJVkdFBfF31rIFYYlKhSgt8Nw/9nCz4sx3lpkzc4Z93q9kMzPnOWfP47gfzsx8z5mvubsAjHznFN0AgNYg7EAQhB0IgrADQRB2IIhzW7mziRMnemdnZyt3CYTS19enQ4cOWaVaQ2E3s3mSVksaJem/3H1lav3Ozk6Vy+VGdgkgoVQqVa3V/TLezEZJelTSDZKulLTEzK6s9/cBaK5G3rNPl/SBu3/k7n+T9HtJC/JpC0DeGgn7pZL2Dnncny37GjPrNrOymZUHBgYa2B2ARjQS9kofAnzj3Ft373X3kruXOjo6GtgdgEY0EvZ+SVOHPP62pH2NtQOgWRoJ+yuSLjOz75jZGEk/krQln7YA5K3uoTd3P25mt0v6owaH3ta6++7cOgOQq4bG2d39WUnP5tQLgCbidFkgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCaGgWV7S/kydPJuvHjh1r6v7Xr19ftXb06NHktm+//Xay/tBDDyXrPT09VWuPPPJIctvzzz8/WV+1alWyfssttyTrRWgo7GbWJ+kLSSckHXf3Uh5NAchfHkf2f3H3Qzn8HgBNxHt2IIhGw+6StprZq2bWXWkFM+s2s7KZlQcGBhrcHYB6NRr2Ge4+TdINkm4zs1mnr+Duve5ecvdSR0dHg7sDUK+Gwu7u+7Lbg5I2SZqeR1MA8ld32M3sQjMbf+q+pLmSduXVGIB8NfJp/GRJm8zs1O/5H3f/31y6GmEOHz6crJ84cSJZf+ONN5L1rVu3Vq19/vnnyW17e3uT9SJ1dnYm6ytWrEjW16xZU7V20UUXJbedOXNmsj5nzpxkvR3VHXZ3/0jSP+XYC4AmYugNCIKwA0EQdiAIwg4EQdiBILjENQf9/f3JeldXV7L+2Wef5dnOWeOcc9LHmtTQmVT7MtRly5ZVrU2aNCm57bhx45L1s/FsUI7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+w5uOSSS5L1yZMnJ+vtPM4+d+7cZL3Wf/vGjRur1s4777zktrNnz07WcWY4sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyz56DWddXr1q1L1p966qlk/dprr03WFy9enKynXHfddcn65s2bk/UxY8Yk65988knV2urVq5PbIl8c2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCHP3lu2sVCp5uVxu2f7OFseOHUvWa41l9/T0VK09+OCDyW23b9+erM+aNStZR3splUoql8tWqVbzyG5ma83soJntGrLsYjN7zszez24n5NkwgPwN52X8OknzTlt2l6Rt7n6ZpG3ZYwBtrGbY3f0FSZ+etniBpPXZ/fWSFubcF4Cc1fsB3WR33y9J2W3VibPMrNvMymZWHhgYqHN3ABrV9E/j3b3X3UvuXjobJ8MDRop6w37AzKZIUnZ7ML+WADRDvWHfImlpdn+ppPR1kAAKV/N6djN7XNJsSRPNrF/SLyStlPQHM1sm6c+SftjMJke6Wt+fXsuECfWPfD788MPJ+syZM5N1s4pDumhDNcPu7kuqlH6Qcy8AmojTZYEgCDsQBGEHgiDsQBCEHQiCr5IeAZYvX1619vLLLye33bRpU7K+e/fuZP2qq65K1tE+OLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs48Aqa+a7u3tTW67bdu2ZH3BggXJ+sKF6a8fnDFjRtXaokWLktty+Wy+OLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBBM2Rxcrevd5807fU7Przt8+HDd+167dm2yvnjx4mR93Lhxde97pGpoymYAIwNhB4Ig7EAQhB0IgrADQRB2IAjCDgTB9ezBTZ8+PVmv9b3xd9xxR7L+5JNPVq3dfPPNyW0//PDDZP3OO+9M1sePH5+sR1PzyG5ma83soJntGrLsHjP7i5ntzH7mN7dNAI0azsv4dZIqnUb1K3fvyn6ezbctAHmrGXZ3f0HSpy3oBUATNfIB3e1m9mb2Mn9CtZXMrNvMymZWHhgYaGB3ABpRb9h/Lem7krok7Ze0qtqK7t7r7iV3L3V0dNS5OwCNqivs7n7A3U+4+0lJv5GU/kgXQOHqCruZTRnycJGkXdXWBdAeal7PbmaPS5otaaKkA5J+kT3ukuSS+iT9zN3319oZ17OPPF999VWy/tJLL1WtXX/99clta/1t3njjjcn6E088kayPRKnr2WueVOPuSyosXtNwVwBaitNlgSAIOxAEYQeCIOxAEIQdCIJLXNGQsWPHJuuzZ8+uWhs1alRy2+PHjyfrTz/9dLL+7rvvVq1dccUVyW1HIo7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+xI2rdvX7K+cePGZP3FF1+sWqs1jl7LNddck6xffvnlDf3+kYYjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTj7CFdryq1HH300WX/ssceS9f7+/jPuabhqXe/e2dmZrJtV/EblsDiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLOfBY4cOZKsP/PMM1Vr9913X3Lb9957r66e8jBnzpxkfeXKlcn61VdfnWc7I17NI7uZTTWz7Wa2x8x2m9nPs+UXm9lzZvZ+djuh+e0CqNdwXsYfl7TC3b8n6Z8l3WZmV0q6S9I2d79M0rbsMYA2VTPs7r7f3V/L7n8haY+kSyUtkLQ+W229pIXNahJA487oAzoz65T0fUl/kjTZ3fdLg/8gSJpUZZtuMyubWbnWedoAmmfYYTezcZI2SFru7n8d7nbu3uvuJXcvdXR01NMjgBwMK+xmNlqDQf+du5/6OtEDZjYlq0+RdLA5LQLIQ82hNxu8TnCNpD3u/sshpS2Slkpamd1ubkqHI8DRo0eT9b179ybrN910U7L++uuvn3FPeZk7d26yfu+991at1foqaC5RzddwxtlnSPqxpLfMbGe2rEeDIf+DmS2T9GdJP2xOiwDyUDPs7r5DUrV/Yn+QbzsAmoXTZYEgCDsQBGEHgiDsQBCEHQiCS1yH6csvv6xaW758eXLbHTt2JOvvvPNOXT3lYf78+cn63Xffnax3dXUl66NHjz7jntAcHNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIgw4+x9fX3J+gMPPJCsP//881VrH3/8cT0t5eaCCy6oWrv//vuT2956663J+pgxY+rqCe2HIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBBFmnH3Dhg3J+po1a5q272nTpiXrS5YsSdbPPTf9v6m7u7tqbezYscltEQdHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Iwtw9vYLZVEm/lfQtSScl9br7ajO7R9JPJQ1kq/a4+7Op31UqlbxcLjfcNIDKSqWSyuVyxVmXh3NSzXFJK9z9NTMbL+lVM3suq/3K3f8zr0YBNM9w5mffL2l/dv8LM9sj6dJmNwYgX2f0nt3MOiV9X9KfskW3m9mbZrbWzCZU2abbzMpmVh4YGKi0CoAWGHbYzWycpA2Slrv7XyX9WtJ3JXVp8Mi/qtJ27t7r7iV3L3V0dOTQMoB6DCvsZjZag0H/nbtvlCR3P+DuJ9z9pKTfSJrevDYBNKpm2M3MJK2RtMfdfzlk+ZQhqy2StCv/9gDkZTifxs+Q9GNJb5nZzmxZj6QlZtYlySX1SfpZUzoEkIvhfBq/Q1KlcbvkmDqA9sIZdEAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSBqfpV0rjszG5D08ZBFEyUdalkDZ6Zde2vXviR6q1eevf2Du1f8/reWhv0bOzcru3upsAYS2rW3du1Lord6tao3XsYDQRB2IIiiw95b8P5T2rW3du1Lord6taS3Qt+zA2idoo/sAFqEsANBFBJ2M5tnZu+a2QdmdlcRPVRjZn1m9paZ7TSzQueXzubQO2hmu4Ysu9jMnjOz97PbinPsFdTbPWb2l+y522lm8wvqbaqZbTezPWa228x+ni0v9LlL9NWS563l79nNbJSk9yT9q6R+Sa9IWuLub7e0kSrMrE9Syd0LPwHDzGZJOiLpt+5+VbbsQUmfuvvK7B/KCe7+723S2z2SjhQ9jXc2W9GUodOMS1oo6Scq8LlL9PVvasHzVsSRfbqkD9z9I3f/m6TfS1pQQB9tz91fkPTpaYsXSFqf3V+vwT+WlqvSW1tw9/3u/lp2/wtJp6YZL/S5S/TVEkWE/VJJe4c87ld7zffukraa2atm1l10MxVMdvf90uAfj6RJBfdzuprTeLfSadOMt81zV8/0540qIuyVppJqp/G/Ge4+TdINkm7LXq5ieIY1jXerVJhmvC3UO/15o4oIe7+kqUMef1vSvgL6qMjd92W3ByVtUvtNRX3g1Ay62e3Bgvv5f+00jXelacbVBs9dkdOfFxH2VyRdZmbfMbMxkn4kaUsBfXyDmV2YfXAiM7tQ0ly131TUWyQtze4vlbS5wF6+pl2m8a42zbgKfu4Kn/7c3Vv+I2m+Bj+R/1DSfxTRQ5W+/lHSG9nP7qJ7k/S4Bl/W/V2Dr4iWSbpE0jZJ72e3F7dRb/8t6S1Jb2owWFMK6u06Db41fFPSzuxnftHPXaKvljxvnC4LBMEZdEAQhB0IgrADQRB2IAjCDgRB2IEgCDsQxP8BwfxNbNfq1cUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지로 출력\n",
    "def show_one_image(n) :\n",
    "    print(type(x_train),x_train.shape)  # (60000, 28, 28)\n",
    "    print(type(y_train),y_train.shape)  # (60000,)\n",
    "    print(type(x_test),x_test.shape)    # (10000, 28, 28)\n",
    "    print(type(y_test),y_test.shape)    # (10000,)\n",
    "\n",
    "    image = x_train[n]\n",
    "    print(y_train[n])\n",
    "    \n",
    "    plt.imshow(image,cmap='Greys')\n",
    "    plt.show()\n",
    "show_one_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 784) <dtype: 'float32'>\n",
      "(10000, 784) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# one-hot 인코딩\n",
    "nb_classes = 10  # 분류(class) 갯수(0~9)\n",
    "\n",
    "Y_one_hot = tf.one_hot(y_train,nb_classes)   # [60000, 10]\n",
    "print(Y_one_hot.shape)                       # [60000, 10], (2차원)\n",
    "\n",
    "# X 값의 shape을 2차원으로 변환\n",
    "x_train = x_train.reshape(-1,28*28)\n",
    "x_test = x_test.reshape(-1,28*28)\n",
    "\n",
    "# X 값의 타입을 float형으로 변환\n",
    "x_train = tf.cast(x_train,dtype=tf.float32)\n",
    "print(x_train.shape,x_train.dtype)\n",
    "\n",
    "x_test = tf.cast(x_test,dtype=tf.float32)\n",
    "print(x_test.shape,x_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layere 1 : 은닉충(Hidden Layer)\n",
    "# (60000, 784) * (784,512) = (60000,512)\n",
    "W1 = tf.Variable(tf.random.normal([784,512]), name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal([512]), name='bias1')\n",
    "\n",
    "def layer1(X):\n",
    "    return tf.sigmoid(tf.matmul(X,W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2 : 은닉충(Hidden Layer)\n",
    "# (60000, 512) * (512,512) = (60000,512)\n",
    "W2 = tf.Variable(tf.random.normal([512,512]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([512]), name='bias2')\n",
    "\n",
    "def layer2(X):\n",
    "    return tf.sigmoid(tf.matmul(layer1(X),W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layere 3 : 은닉충(Hidden Layer)\n",
    "# (60000, 512) * (512,512) = (60000,512)\n",
    "W3 = tf.Variable(tf.random.normal([512,512]), name='weight3')\n",
    "b3 = tf.Variable(tf.random.normal([512]), name='bias3')\n",
    "\n",
    "def layer3(X):\n",
    "    return tf.sigmoid(tf.matmul(layer2(X),W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layere 4 : 출력층(output Layer)\n",
    "# (60000, 512) * (512,10) = (60000,10)\n",
    "W4 = tf.Variable(tf.random.normal([512,nb_classes]), name='weight4')\n",
    "b4 = tf.Variable(tf.random.normal([nb_classes]), name='bias4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수(hypothesis) : H(X) = sigmoid(W*X + b)\n",
    "# tf.sigmoid() : tf.div(1.,1. + tf.exp(-tf.matmul(X,W) + b))\n",
    "def logits(X):\n",
    "    return tf.matmul(layer3(X),W4) + b4\n",
    "\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(logits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수 구현 방법 : tf.nn.softmax_cross_entropy_with_logits() 함수 사용\n",
    "def cost_func():\n",
    "    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(x_train),\n",
    "                                             labels = Y_one_hot) # Y_one_hot으로\n",
    "    cost =  tf.reduce_mean(cost_i)\n",
    "    return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01 로 설정하여 optimizer객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['weight:0', 'bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9f987a8e949f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# cost를 minimize 한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \"\"\"\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m   1023\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[1;32m-> 1025\u001b[1;33m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[0;32m   1026\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m     logging.warning(\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: ['weight:0', 'bias:0']."
     ]
    }
   ],
   "source": [
    "# # 학습 시작\n",
    "# print('***** Start Learning!!')\n",
    "# for step in range(2001):\n",
    "#     # cost를 minimize 한다\n",
    "#     optimizer.minimize(cost_func,var_list=[W,b])\n",
    "    \n",
    "#     if step % 100 == 0:\n",
    "#         print('%04d'%step,'cost:[',cost_func().numpy(),']')\n",
    "# print('***** Learning Finished!!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수, weight과 bias 출력\n",
    "# print('Weight:',W.numpy())\n",
    "# print('Bias:',b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "Accuracy: 0.103\n",
      "******* Predict\n",
      "[8 8 8 ... 8 4 2] [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정 : accuracy computation\n",
    "\n",
    "# y_test 값의 one-hot 인코딩\n",
    "Y_one_hot = tf.one_hot(y_test,nb_classes)   # [None,1,7]\n",
    "print(Y_one_hot.shape)                       # [70,1,7]  , Rank=3 (3차원)\n",
    "\n",
    "# 예측\n",
    "# tf.argmax() : 값이 가장 큰 요소의 인덱스 값을 반환\n",
    "def predict(X):\n",
    "    return tf.argmax(hypothesis(X),axis=1)\n",
    "\n",
    "correct_predict = tf.equal(predict(x_test),tf.argmax(Y_one_hot,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, dtype = tf.float32))\n",
    "print(\"Accuracy:\",accuracy.numpy())\n",
    "\n",
    "# 예측\n",
    "print('******* Predict')\n",
    "\n",
    "pred = predict(x_test).numpy()\n",
    "print(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "Epoch: 0001 cost: 2.141143994\n",
      "Epoch: 0002 cost: 0.550809027\n",
      "Epoch: 0003 cost: 0.450334351\n",
      "Epoch: 0004 cost: 0.387223292\n",
      "Epoch: 0005 cost: 0.352307557\n",
      "Epoch: 0006 cost: 0.331453468\n",
      "Epoch: 0007 cost: 0.312413388\n",
      "Epoch: 0008 cost: 0.300371652\n",
      "Epoch: 0009 cost: 0.288413459\n",
      "Epoch: 0010 cost: 0.271099162\n",
      "Epoch: 0011 cost: 0.262326759\n",
      "Epoch: 0012 cost: 0.254034078\n",
      "Epoch: 0013 cost: 0.259018162\n",
      "Epoch: 0014 cost: 0.259080120\n"
     ]
    }
   ],
   "source": [
    "# 방법 2. batch 사이즈로 나누어 학습, 효율적 이며 학습 시간 단축\n",
    "# 학습 시작\n",
    "\n",
    "training_epoch = 25\n",
    "batch_size = 600\n",
    "\n",
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01 로 설정하여 optimizer객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "Y_one_hot = tf.one_hot(y_train,nb_classes)   # (60000, 10)\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for epoch in range(training_epoch): # 25회\n",
    "    \n",
    "    avg_cost = 0\n",
    "    \n",
    "    # 100 = 60000/600\n",
    "    total_batch = int(x_train.shape[0]/batch_size)\n",
    "    for k in range(total_batch):  # 100회\n",
    "        batch_xs = x_train[0 + k*batch_size:batch_size + k*batch_size]   # 600개의 X 데이터\n",
    "        batch_ys = Y_one_hot[0 + k*batch_size:batch_size + k*batch_size] # 600개의 Y 데이터\n",
    "        \n",
    "        # 비용함수        \n",
    "        def cost_func_batch():\n",
    "            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(batch_xs),\n",
    "                                             labels = batch_ys)\n",
    "            cost =  tf.reduce_mean(cost_i)\n",
    "            return cost\n",
    "        \n",
    "        # cost를 minimize 한다\n",
    "        optimizer.minimize(cost_func_batch,var_list=[W1,b1,W2,b2,W3,b3,W4,b4])\n",
    "        avg_cost += cost_func_batch().numpy()/total_batch\n",
    "            \n",
    "    print('Epoch:','%04d'%(epoch + 1),'cost:','{:.9f}'.format(avg_cost))\n",
    "             \n",
    "print('***** Learning Finished!!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "Accuracy: 0.8953\n",
      "******* Predict\n",
      "[7 2 1 ... 4 5 6] [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정 : accuracy computation\n",
    "\n",
    "# y_test 값의 one-hot 인코딩\n",
    "Y_one_hot = tf.one_hot(y_test,nb_classes)   # [None,1,7]\n",
    "print(Y_one_hot.shape)                       # [70,1,7]  , Rank=3 (3차원)\n",
    "\n",
    "# 예측\n",
    "# tf.argmax() : 값이 가장 큰 요소의 인덱스 값을 반환\n",
    "def predict(X):\n",
    "    return tf.argmax(hypothesis(X),axis=1)\n",
    "\n",
    "correct_predict = tf.equal(predict(x_test),tf.argmax(Y_one_hot,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, dtype = tf.float32))\n",
    "print(\"Accuracy:\",accuracy.numpy())\n",
    "\n",
    "# 예측\n",
    "print('******* Predict')\n",
    "\n",
    "pred = predict(x_test).numpy()\n",
    "print(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random = 1850 Label: 8\n",
      "Prediction [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOEElEQVR4nO3db6yU5ZnH8d9P1mqCxehydAklUoyJwKq0jASDaTR1GzQabEJNiUFMdOkL1NbUuOq+qC/NZmvTFxuVrqZUVKxRIkayWzWi1j/EwZwVFHdxCVsQAgdFa6PSFa59cYbNAc/cc5j/Pdf3k5zMzHPNM/fFhN955sz9zNyOCAEY/07odQMAuoOwA0kQdiAJwg4kQdiBJP6qm4NNnjw5pk+f3s0hgVR27Nih/fv3e7RaS2G3vVDSLyVNkPSvEXFP6f7Tp09XtVptZUgABZVKpW6t6ZfxtidI+hdJl0uaJWmJ7VnNPh6Azmrlb/Z5kt6PiO0R8WdJayQtak9bANqtlbBPlbRzxO1dtW1Hsb3cdtV2dWhoqIXhALSilbCP9ibAV869jYiVEVGJiMrAwEALwwFoRSth3yVp2ojb35C0u7V2AHRKK2F/U9I5tr9p+2uSfihpXXvaAtBuTU+9RcSXtm+S9O8annp7KCLeaVtnANqqpXn2iFgvaX2begHQQZwuCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiipSWbbe+Q9KmkQ5K+jIhKO5oC0H4thb3m0ojY34bHAdBBvIwHkmg17CHpd7Y32V4+2h1sL7ddtV0dGhpqcTgAzWo17Asi4tuSLpe0wvZ3jr1DRKyMiEpEVAYGBlocDkCzWgp7ROyuXe6TtFbSvHY0BaD9mg677Ym2v37kuqTvSdrSrsYAtFcr78afKWmt7SOP82hE/FtbuhpnPvnkk2J97969xfr27duL9U2bNtWtHThwoLjvhx9+WKw/8sgjxfott9xSrJdcc801xfq8ebxQbKemwx4R2yVd0MZeAHQQU29AEoQdSIKwA0kQdiAJwg4k4Yjo2mCVSiWq1WrXxusXl156abH+0ksvdamT/lKbtq3ryiuvLNYfffTRYn3ixInH3dNfukqlomq1OuoTy5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JoxxdOooGpU6f2uoW6Gp0DcN5557X0+A888EDd2sGDB4v7PvPMM8X6E088Uaxff/31xXo2HNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnm2bvg4YcfLtYPHz5crK9Zs6bpsZ999tlifeHChcV6o8+cN3Lvvfc2ve+KFSuK9Q0bNhTrzLMfjSM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBPHsXNJqrvv/++4v1Q4cOFetr166tW1uyZElx39WrVxfrjb67vZETTqh/PGn07xocHCzWP//886Z6yqrhkd32Q7b32d4yYtvptp+zva12eVpn2wTQqrG8jP+1pGNPs7pD0gsRcY6kF2q3AfSxhmGPiJclfXTM5kWSVtWur5J0dZv7AtBmzb5Bd2ZE7JGk2uUZ9e5oe7ntqu3q0NBQk8MBaFXH342PiJURUYmIysDAQKeHA1BHs2Hfa3uKJNUu97WvJQCd0GzY10laVru+TNLT7WkHQKc0nGe3/ZikSyRNtr1L0s8k3SPpt7ZvkPQHST/oZJPj3aRJk4r1xx9/vFgvfb/6zTffXNx36dKlxfprr71WrM+cObNYL2n0Of6NGzcW6+eff37TY2fUMOwRUe+sjO+2uRcAHcTpskAShB1IgrADSRB2IAnCDiTBR1zHgauuuqpubcaMGcV9L7jggmJ9wYIFxfru3buL9ZNPPrlu7c477yzu20ijr5rG0TiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASzLOPc7Nnzy7WGy0nfd111xXrixcvLtZvvfXWurX77ruvuO+JJ55YrF944YXFOo7GkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCePblGSzrv3LmzWL/jjvKanuvXrz/uno5otJz0nDlzmn7sjDiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjoiuDVapVKJarXZtPLTus88+K9ZPOeWUph+70efVP/jgg2J98uTJTY89XlUqFVWrVY9Wa3hkt/2Q7X22t4zYdrftD2wP1n6uaGfDANpvLC/jfy1p4SjbfxERc2o/zZ8mBaArGoY9Il6W9FEXegHQQa28QXeT7bdrL/NPq3cn28ttV21Xh4aGWhgOQCuaDft9ks6WNEfSHkk/r3fHiFgZEZWIqAwMDDQ5HIBWNRX2iNgbEYci4rCkX0ma1962ALRbU2G3PWXEze9L2lLvvgD6Q8PPs9t+TNIlkibb3iXpZ5IusT1HUkjaIelHHewRPfTKK6907LGXLVtWrDOP3l4Nwx4Ro327wYMd6AVAB3G6LJAEYQeSIOxAEoQdSIKwA0nwEdfkPv7442L97LPPLtYPHDjQ9NgTJkwo1t97771ivVFvGbX0EVcA4wNhB5Ig7EAShB1IgrADSRB2IAnCDiTBks3j3MGDB4v1p556qlhvNI9+6qmnFuuvv/563drcuXOL+z755JPF+u23316s42gc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZx7nBwcFi/cYbbyzWTzrppGL91VdfLdbPPffcurX58+cX93333XeLdRwfjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7OPczp07W9p/9uzZxfqsWbNaevySs846q2OPnVHDI7vtabZftL3V9ju2f1zbfrrt52xvq12e1vl2ATRrLC/jv5T004iYKWm+pBW2Z0m6Q9ILEXGOpBdqtwH0qYZhj4g9EfFW7fqnkrZKmippkaRVtbutknR1p5oE0LrjeoPO9nRJ35K0UdKZEbFHGv6FIOmMOvsst121XR0aGmqtWwBNG3PYbZ8i6UlJP4mIP451v4hYGRGViKgMDAw00yOANhhT2G2fqOGgPxIRR76OdK/tKbX6FEn7OtMigHZoOPVm25IelLQ1Iu4dUVonaZmke2qXT3ekQzR0+PDhurU1a9YU9502bVqx/vzzzzfV0xH79++vW9u2bVtx35kzZ7Y0No42lnn2BZKWStps+8iHo+/ScMh/a/sGSX+Q9IPOtAigHRqGPSJ+L2nUxd0lfbe97QDoFE6XBZIg7EAShB1IgrADSRB2IAk+4joOfPHFF3VrjZZkvvjii4v1SZMmFeubN28u1hcvXly3tmvXruK+1157bbGO48ORHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ59HGg0112ydevWYv2yyy4r1jds2ND02LfddluxftFFFzX92PgqjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7ONA6fvVJ06cWNy39L3uUmvz6JL0xhtv1K3NnTu3pcfG8eHIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJjGV99mmSfiPpbyQdlrQyIn5p+25Jfy9pqHbXuyJifacaRX2l73ZfvXp1cd8XX3yxWG80Fz5//vxifcaMGXVrEyZMKO6L9hrLSTVfSvppRLxl++uSNtl+rlb7RUT8c+faA9AuY1mffY+kPbXrn9reKmlqpxsD0F7H9Te77emSviVpY23TTbbftv2Q7dPq7LPcdtV2dWhoaLS7AOiCMYfd9imSnpT0k4j4o6T7JJ0taY6Gj/w/H22/iFgZEZWIqAwMDLShZQDNGFPYbZ+o4aA/EhFPSVJE7I2IQxFxWNKvJM3rXJsAWtUw7LYt6UFJWyPi3hHbp4y42/clbWl/ewDaZSzvxi+QtFTSZtuDtW13SVpie46kkLRD0o860iFasmjRopbqGD/G8m787yV5lBJz6sBfEM6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6N5g9pCk/xmxabKk8prBvdOvvfVrXxK9NaudvZ0VEaN+/1tXw/6Vwe1qRFR61kBBv/bWr31J9NasbvXGy3ggCcIOJNHrsK/s8fgl/dpbv/Yl0VuzutJbT/9mB9A9vT6yA+gSwg4k0ZOw215o+z9tv2/7jl70UI/tHbY32x60Xe1xLw/Z3md7y4htp9t+zva22uWoa+z1qLe7bX9Qe+4GbV/Ro96m2X7R9lbb79j+cW17T5+7Ql9ded66/je77QmS/kvS30naJelNSUsi4t2uNlKH7R2SKhHR8xMwbH9H0p8k/SYi/ra27Z8kfRQR99R+UZ4WEf/QJ73dLelPvV7Gu7Za0ZSRy4xLulrS9erhc1fo6xp14XnrxZF9nqT3I2J7RPxZ0hpJLEsyioh4WdJHx2xeJGlV7foqDf9n6bo6vfWFiNgTEW/Vrn8q6cgy4z197gp9dUUvwj5V0s4Rt3epv9Z7D0m/s73J9vJeNzOKMyNijzT8n0fSGT3u51gNl/HupmOWGe+b566Z5c9b1Yuwj7aUVD/N/y2IiG9LulzSitrLVYzNmJbx7pZRlhnvC80uf96qXoR9l6RpI25/Q9LuHvQxqojYXbvcJ2mt+m8p6r1HVtCtXe7rcT//r5+W8R5tmXH1wXPXy+XPexH2NyWdY/ubtr8m6YeS1vWgj6+wPbH2xolsT5T0PfXfUtTrJC2rXV8m6eke9nKUflnGu94y4+rxc9fz5c8jous/kq7Q8Dvy/y3pH3vRQ52+Zkj6j9rPO73uTdJjGn5Z978afkV0g6S/lvSCpG21y9P7qLeHJW2W9LaGgzWlR71drOE/Dd+WNFj7uaLXz12hr648b5wuCyTBGXRAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/AZ1aPZ6ufJ2dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 임의의 test 데이터로 예측한 값 시각화하기\n",
    "r = np.random.randint(0,x_test.shape[0] - 1)  # 0 to 9999 random int number\n",
    "print('random =',r,'Label:',y_test[r])\n",
    "\n",
    "print('Prediction',predict(x_test[r:r+1]).numpy())\n",
    "\n",
    "image = tf.reshape(x_test[r],(28,28))\n",
    "plt.imshow(image,cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 비교\n",
    "# 1 Layer                  ------> Accuracy : 0.8871\n",
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
