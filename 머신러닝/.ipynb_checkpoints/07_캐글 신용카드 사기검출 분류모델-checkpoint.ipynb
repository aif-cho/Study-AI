{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글 신용카드 사기 검출 분류 모델\n",
    "#### 데이터 1차 가공 및 모델 학습 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # warning 메세지 출력을 하지 않도록설정\n",
    "\n",
    "# https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets/notebook\n",
    "\n",
    "card_df =pd.read_csv('./creditcard.csv')\n",
    "card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 'Time' 컬럼만 삭제\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.drop('Time',axis = 1, inplace =True)\n",
    "    print(df_copy.shape)\n",
    "    print(df_copy.iloc[:,-1].value_counts())\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 세트를 분리하여 반환 : [70:30]\n",
    "def get_train_test_dataset(df=None):\n",
    "    df_copy = get_preprocessed_df(df)\n",
    "    \n",
    "    X_features = df_copy.iloc[:,:-1]\n",
    "    y_target = df_copy.iloc[:,-1]\n",
    "    \n",
    "    # Stratified 방식으로 추출  (0과 1 비율이  0.998:0.001)\n",
    "    X_train,X_test,y_train,y_test = \\\n",
    "    train_test_split(X_features,y_target, test_size=0.3,random_state=0, stratify=y_target)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X_train,X_test,y_train,y_test = get_train_test_dataset(card_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train 데이터 레이불 값 비율')\n",
    "print(y_train.value_counts()/y_train.shape[0] * 100)\n",
    "\n",
    "print('test 데이터 레이불 값 비율')\n",
    "print(y_test.value_counts()/y_test.shape[0] * 100)\n",
    "# y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)   \n",
    "    roc_auc = roc_auc_score(y_test,pred)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy,precision,recall,f1,roc_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()  # 0과 1 처럼 2진 분류\n",
    "\n",
    "# 학습(training)\n",
    "lr_clf.fit(X_train,y_train)\n",
    "\n",
    "# 예측(prdict)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "get_clf_eval(y_test,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자로 사이킷런의 Estimator객체와, 학습/테스트 데이터 세트를 입력 받아서 학습/예측/평가 수행.\n",
    "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "    model.fit(ftr_train, tgt_train)\n",
    "    pred = model.predict(ftr_test)\n",
    "    get_clf_eval(tgt_test, pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터의 분포를 변환하여 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(range(0,30000,1000),rotation=60)\n",
    "sns.distplot(card_df['Amount'])  # 카드 사용금액\n",
    "plt.show()\n",
    "card_df['Amount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규분포 형태로 변환\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1,1))\n",
    "    df_copy.insert(0,'Amount_Scaled',amount_n)  # 변환된 결과를 0번 컬럼에  추가\n",
    "    df_copy.drop(['Time','Amount'], axis=1,inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "df_copy = get_preprocessed_df(card_df)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(range(0,200,10),rotation=60)\n",
    "sns.distplot(df_copy['Amount_Scaled'])  # 카드 사용금액\n",
    "plt.show()\n",
    "df_copy['Amount_Scaled'].value_counts()\n",
    "df_copy['Amount_Scaled'].max()\n",
    "\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Amount'를 정규분포 형태로 변환 후 학습및 예측 수행\n",
    "X_train,X_test,y_train,y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "lr_clf = LogisticRegression()\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "# 결과: 성능 개선이 거의 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## log 변환 후 학습및 예측 수행\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    amount_n = np.log1p(df_copy['Amount'])   # np.log(0) = 무한대, np.log1p(0) ==> np.log(0 + 1)\n",
    "    df_copy.insert(0,'Amount_Scaled',amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1,inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "df_copy = get_preprocessed_df(card_df)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(range(0,100,1),rotation=60)\n",
    "sns.distplot(df_copy['Amount_Scaled'])  # 카드 사용금액\n",
    "plt.show()\n",
    "df_copy['Amount_Scaled'].value_counts()\n",
    "df_copy['Amount_Scaled'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log 변환 후 학습및 예측 수행\n",
    "X_train,X_test,y_train,y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "# LightGBM 결과: 약간 성능 개선  , AUC:0.8783 --> AUC:0.8817"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 제거 후  모델 학습및 예측 수행\n",
    "## IQR(Inter Quantile Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "corr = card_df.corr()\n",
    "sns.heatmap(corr,cmap='RdBu')\n",
    "plt.show()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_outlier(df=None,column=None, weight=1.5):\n",
    "    # fraud에 해당하는 column 데이터만 추출, 1/4 분위수와 3/4 분위수를 np.percentile로 구함\n",
    "    fraud =  df[df['Class'] == 1][column]\n",
    "    quantile_25 = np.percentile(fraud.values,25)   # Q1\n",
    "    quantile_75 = np.percentile(fraud.values,75)   # Q3\n",
    "    \n",
    "    iqr = quantile_75 - quantile_25\n",
    "    \n",
    "    lowest_val = quantile_25 - iqr*weight   # 최소값 지점  : Q1 - IQR*1.5\n",
    "    highest_val = quantile_75 + iqr*weight   # 최대값 지점 : Q3 + IQR*1.5\n",
    "    print(lowest_val,highest_val)\n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    return outlier_index\n",
    "\n",
    "#     normal_data = fraud[(fraud >= lowest_val) & (fraud <= highest_val)] # 극단치가 아닌값만 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index = get_outlier(df=card_df, column='V14',weight=1.5)\n",
    "print('이상치 인덱스:',outlier_index)\n",
    "card_df['V14'][outlier_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## log 변환 및 이상치 제거 학습및 예측 수행\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    amount_n = np.log1p(df_copy['Amount'])   # np.log(0) = 무한대, np.log1p(0) ==> np.log(0 + 1)\n",
    "    df_copy.insert(0,'Amount_Scaled',amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1,inplace=True)\n",
    "   \n",
    "    # 이상치 데이터 행을 모두 삭제하는 코드를 추가\n",
    "    outlier_index = get_outlier(df=card_df, column='V14',weight=1.5)\n",
    "    df_copy.drop(outlier_index,axis=0,inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "# log 변환 및 이상치 제거후 학습및 예측 수행\n",
    "X_train,X_test,y_train,y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "# LightGBM 결과: 성능 크게 개선  , AUC:0.8817 --> AUC:0.9144\n",
    "\n",
    "# 'V17' 등 상관계수 값이 큰 컬럼들의 이상치를 제거하여 모델을 구현하면 성능 향상 기대됨(로그변환 포함):숙제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE(Synthetic Minority Over-Sampling Technique)오버 샘플링 적용 후 모델 학습/예측/평가\n",
    "#### : 적은 데이터셋을 증식하여 학습을 위한 충분한 데이터를 확보\n",
    "#### https://mkjjo.github.io/python/2019/01/04/smote_duplicate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over,y_train_over = smote.fit_sample(X_train,y_train)\n",
    "\n",
    "print('SMOTE 적용 전 데이터: ',X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 데이터: ',X_train_over.shape, y_train_over.shape)\n",
    "\n",
    "print('SMOTE 적용 전 레이블 값 분포:\\n ', y_train.value_counts())\n",
    "print('SMOTE 적용 후 레이블 값 분포:\\n ', pd.Series(y_train_over).value_counts())    # 50:50으로 label이 재 설정\n",
    "# print(type(y_train_over))  # ndarray 는 value_counts() 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)\n",
    "\n",
    "# LightGBM 결과: 성능 크게 개선\n",
    "# SMOTE를 적용하면 재현율은 높아지나 정밀도는 낮아짐 (실제 원본 보다 Class=1 인 데이터를  너무 많이 학습한 결과임)\n",
    "# https://joonable.tistory.com/27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비지도 학습: 차원 축소, 군집화\n",
    "#### 차원 축소 : PCA(Principle component Analysis,주성분 분석)\n",
    "####   이미지 데이터, 자연언어 텍스트 의미 분석, 과적합(Overfitting)을 방지할수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 변환\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 7) # 축소될 차원 설정 : 7차원\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "print('PCA 차원 축소 전:', X_train.shape)\n",
    "print('PCA 차원 축소 후:', X_train_pca.shape)\n",
    "\n",
    "pca.fit(X_test)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print('PCA 차원 축소 전:', X_test.shape)\n",
    "print('PCA 차원 축소 후:', X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train_pca, ftr_test=X_test_pca, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train_pca, ftr_test=X_test_pca, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "# LightGBM 결과:  개선 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 변환 , SMOTE 오버샘플링 데이터 사용\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 7) # 축소될 차원 설정 : 7차원\n",
    "pca.fit(X_train_over)\n",
    "X_train_pca = pca.transform(X_train_over)\n",
    "print('PCA 차원 축소 전:', X_train_over.shape)\n",
    "print('PCA 차원 축소 후:', X_train_pca.shape)\n",
    "\n",
    "pca.fit(X_test)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print('PCA 차원 축소 전:', X_test.shape)\n",
    "print('PCA 차원 축소 후:', X_test_pca.shape)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train_pca, ftr_test=X_test_pca, tgt_train=y_train_over, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train_pca, ftr_test=X_test_pca, tgt_train=y_train_over, tgt_test=y_test)\n",
    "\n",
    "# LightGBM 결과:  개선 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
